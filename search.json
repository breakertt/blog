[{"title":"博文坑表","date":"2020-10-27T03:20:00.000Z","url":"/2020/10/27/blog_ideas/","categories":["Life"],"content":"开坑一时爽。 这个坑表主要有两个目的： 帮助记忆要写的东西 督促自己写点博文 文章 添加日期 完成日期 GPU 过热掉卡后的手动转速接管 2020/10/27 N/A 2020 实习感悟 2020/10/27 N/A 无公网 IPv4 给局域网配置 IPv6 2020/10/27 N/A "},{"title":"UoN 学生跑毒（COVID-19）指北","date":"2020-03-18T08:30:00.000Z","url":"/2020/03/18/covid-19_back_to_china/","tags":["COVID-19","Univeristy"],"categories":["Life"],"content":"因新冠肺炎回国信息共享，持续更新。 机票购买尽量购买行李直挂，转机少的航班。然后现在很多航班都在取消，有小道消息说星期一三五的常规航班是不会取消的。 转机详情请询问自己的航司！！！ 我是一名英国留学研究生，鉴于英国现在的疫情情况我该不该回国？ - Ruoning的回答 - 知乎 到国内 记得在当地政府那边提前备案 准备好支付宝健康码 让家人找出医保卡 宁诺学生好像是一开始就交了四年的 生活住房我把东西放在朋友那边了，大家也做好下学年回来的准备吧。 居留（签证）政府可以看看这个（Coronavirus (COVID-19): immigration guidance ）网页？ 学校今天去了趟 Cherry Tree Lodge，那边的答复是他们也不知道怎么办，但是因为 COVID-19 的话应该会豁免吧。 然后我问：“那学校那边我想报备一下应该找谁呢？”，他们回复我让我发邮件给 immigration-support@nottingham.ac.uk 。内容应该包括： 你的学号 你的名字 你的专业 你的目的地国家 你的预计出发/返回 然后再附上一个别人问到的： 学业Personal Tutor记得和你的 PT 说一声你要回国比较好哦！ Coursework - Extenuating circumstances因为回国的话很有可能一入境就被隔离，隔离的环境也是未知的。作为严重依赖StackOverflow互联网的计算机科学学生，如果隔离的地方没有网络的话，对于做作业是致命的打击。 所以我去咨询了 Student Service Center 关于申请 EC 的事宜。那边的专员表示可以申请 EC，然后有两种申请情况： 被隔离了，隔离完去申请，附上相关证明 还没有被隔离，现在先申请，之后补证明 关于申请方法就是填表，链接是这个：Extenuating circumstances form ，其他信息在这里可以找到。 关于 EC 申请的进度，专员让我给 ss-assessments-jc@nottingham.ac.uk 发邮件。 Final ExamUoN 安排Student Service Center表示不确定，说是可能会变成线上考试。 Group Project Supervisor他就说可能九月之前都不会有线下活动了。。。。 海外考试官方网页：How to apply for overseas examinations UNUK 这边的申请 - 截止2019.03.16仍可申请 查能不能海外考 - Check if your UNUK exams MSExcelconcan or cannot be taken overseas 填申请表 - Overseas Exam Form UNNC - 默认你是想要在宁诺考我目前就是给 UNNC 的 exams@nottingham.edu.cn 发了邮件，内容如图，英语渣请谅解。 我这边建议你多说一句已经在 UNUK 申请了，顺便把 UNUK 的申请表回执邮件附上。"},{"title":"使用 VPS 把 HE IPv6 地址 WireGuard 分配给 Windows 客户端使用","date":"2020-03-14T06:43:30.000Z","url":"/2020/03/14/hev6_wireguard/","tags":["Linux"],"categories":["Network"],"content":"把 HE 给你的 IPv6 通过 VPS 带回家吧！ 前言最近呢，发现自己其实对网络一窍不通。之前玩了很久的应用层和传输层，但是对网络层和接口着实是捉襟见肘。前两天看到了 Dr.Cai 发的BGP速成，打算也来搞个玩玩。 但是我的想法是，并没有要一下去就去上 BGP 玩，正好 HE 的 6in4 隧道会分配一个 /64 甚至是 /48 的 v6 段，那不如先拿这个来玩玩。搞定了这个再去搞那些和 BGP 有关系的广播等高级操作。 不过要说一句的是，本人目前在墙外，国内我不知道是否可以这样搞！ 注册 tunnelbroker这个有很多博文讲过如何操作了，就不赘述了,可以参考这篇。 VPS(CentOS 7) 配置 IPv6 隧道解除 IPv6 限制（可选）这里我们要在/etc/sysctl.conf加入这几行。 设置隧道用的 interface新建/etc/sysconfig/network-scripts/ifcfg-sit1，编辑如下内容： 这边再提供一个虚拟样例： 如果本机没有原生 IPv6 的话，我们就可以在这里ifup sit1，然后 curl  看看自己的 v6 是否已经通了。如果有原生 IPv6 的话，看一下后面我的解决。 原生 v6 的追加配置设置默认 v6 出口为 sit1 这边我遇到了一个小坑，我的 VPS 商用了 cloud-init 导致每次重启会重写这个文件，解决方法是运行如下命令： 关闭原生 interface 的 v6 功能在 /etc/sysctl.conf 中加入 net.ipv6.conf.&lt;your default interface&gt;.disable_ipv6 = 1 也许是个不错的办法。 配置WireGuard服务端一键安装这边我们就先直接用一键脚本进行 WireGurad 的安装，执行如下命令： 如果要换内核的话请先换内核在进行安装。 这个脚本自动配置了客户端和服务端的密码以及配置，讲道理是可以直接用的，但是这并不是我们想要的。我们这边只是要本地分配到 IPv6 然后 v6 地址通过 WireGuard 访问，所以还要进一步配置。 首先我们启用一波自动 WireGuard 的自动开机啥的： 编辑 wg0.conf编辑 /etc/wireguard/wg0.conf 为如下： 这里的地址前缀中取一个地址出来写到 AllowedIPs 里面，因为我们就用一台电脑登陆，::1/128 就是个不错的选择。至于 PublicKey 和 PrivateKey 就按照原来就好。 然后我们就可以用 wg-quick up wg0 来暂时开启 WireGuard 服务并配置客户端。 Windows 客户端这边我选择了 TunSafe 作为我的客户端，下载地址： 。 安装完成之后，我们点一下主界面的 Edit Config，然后先把服务器端自动生成在 /etc/wireguard/client.conf 中的内容拷贝过来。 然后，把 Interface 中的 Address 改为 10.0.0.2/32, &lt;Routed /64&gt;::1/128 ; Peer 中的 AllowedIPs 改为 10.0.0.2/24, ::0/0, 这样的话我们 v4 除了 WireGuard 内网都走本地， v6 全部走 WireGuard。 最终配置如下： 然后尝试链接，用浏览器打开  看看有没有得到自己的 v6 段下的地址。 收尾工作在服务端运行如下脚本，进行长期运行： 结语之后的打算还有不少，就先把 flag 立起来吧。 给 R6300v2 安装 OpenWrt 并用 WireGuard 分配整个网段的 IPv6 给本地局域网的设备 找一种比 WireGuard 更好的组网方式（可以透过GFW) 注册ASN，宣告自己的 IP 地址并用之前的方法把这些 IP 带回家 参考资料 how-to-get-rid-of-cloud-init 科学上网指南(10)——wireguard 将宣告的 subnet 通过 wireguard 分配给客户端使用 CentOS 安装最新版的Wireguard CentOS7一键脚本安装WireGuard "},{"title":"Baidupcs-web 在 apache2 上的反向代理配置","date":"2019-08-20T08:10:00.000Z","url":"/2019/08/20/baidupcsgo-web-proxy/","tags":["Network","Proxy"],"categories":["Linux"],"content":"此处省略一万句脏话。 最近被安利了一个webui版本的baidupcs-go，叫做BiaduPCS-Web，据说不错我就也来用用。 安装很容易，使用了GitHub上的一键脚本： 但是服务起来之后用的是5299端口，不太优雅对吧？那我就想着做个反代好了，也就是本文的重点了。 一开始我是想配一个类似于”;, 这样的子目录的反向代理的，但是这个软件不支持baseURL的配置以及路径都是写死的，那就只能单开一个域名给这个软件了。如果您使用的http服务器是nginx请看这里：请问如何用nginx进行反向代理，caddy我也不太清楚，反正这篇文章讲的只有apache的。 这个软件有部分链接用的不是http，而是websocket，这就是问题所在了，查了不少资料，我们需要先开启用几个插件： 然后添加如下的新站点，只开了443的，80请自己改，内容如下： 简单讲一下，这边把当http请求需要升级为ws请求时，把反代的头改成了ws，然后就可以成功访问了。"},{"title":"在 Ubuntu18.04 上使用 clash 部署旁路代理网关（透明代理）","date":"2019-08-20T06:10:00.000Z","url":"/2019/08/20/clash_gateway/","tags":["Network","Proxy"],"categories":["Linux"],"content":"Apple TV 4K 到货前的准备工作 最近打算购入一台 Fire TV 4K, 又因为众所周知的原因, Fire TV 4k 在没有代理的情况下是根本没法用的，所以就萌生了拿之前买的 nuc 来做一个旁路代理网关的想法。 在Ubuntu上部署一个透明代理网关主要是三块：安装 clash, 简单配置 clash， 高级配置 clash, 配置 iptables 转发。 安装 clash使用 clash 的最主要原因是它自带 redir 服务，且使用 go 语言开发安装非常方便。 然后我们把 clash 设置成 service，下面是我的/etc/systemd/system/clash.service 然后我们把clash激活为开机启动 简单配置 clash在这个环节中主要是简单配置 clash 及其 dashboard，让其能作为一个局域网的代理服务器存在。 然后我们给config.yaml加上内容： 然后我们执行service clash start，就有一个可以使用的局域网代理服务器了，甚至可以在浏览器里面访问来调试 clash！如果是公网的话我推荐 secret 处加上内容以保证安全性。 高级配置 clash这里的配置主要是两块： clash dns因为我们要拿 clash 做一个透明网关，那么 dns 服务必然是一个问题，clash 自带的 dns 服务很神奇，我研究了一个上午，如果想了解可以看这两篇文章：DNS污染对Clash（for Windows）的影响，代替 Surge 增强模式——使用 KoolClash 作为代理网关 最后我用的就是第一篇文章中所用到的方案，在 clash 的设置文件中加入了以下内容： 为什么不用 fake-ip 呢？因为我觉得目前的 redir-host 方案足够我本人使用了。 国内外分流clash 这个软件的一大特色就是他的分流功能，所以我想还是得用起来，不说好用，至少可以堪用。 然后我就找到了网上已经有现成的规则文件了，可以抄过来用。 如果需要分流的话就把这个文件中的 rules 部分抄进目前的config.yaml。 配置iptables转发这是我们的最后一步，主要是使用 iptables 配置 nat 的转发到 clash，很大一部分都是参考了 Clash TProxy Mode，不过这里面的规则有问题，会导致 dns 的回环。 最后修复后的规则如下，这个规则网关本身是不走代理的，反正我可以用 proxychains-ng 对本机进行代理： 规则持久化当然我们还不希望这些规则重启就没，那么我们就需要安装一些辅助工具来持久化iptables的规则： 具体可以看这里：how-to-save-rules-of-the-iptables 一个问题我遇到了主路由映射端口无效的问题，加了一行 iptables 规则就好了。如果还没好的话，把你需要访问的服务在内网 bind 的端口加到下面的这行里面。 尾声那么就可以把旁路网关地址以及dns设置在需要的机器上了！我也要开始下单 Apple TV 了！"},{"title":"使用AegiSub和FFmpeg为视频打上字幕(啊？Pr是什么？)","date":"2018-10-16T05:41:30.000Z","url":"/2018/10/16/encoded_subtitle/","tags":["FFmpeg","VideoTech"],"categories":["Media"],"content":"SESA干培。 工具的准备1. Aegisub请访问Aegisub官网对应系统进行下载以及安装 2. FFMpegWindows用户: 下载FFMpeg:  (请选择static版本) 解压FFmpeg: 把下载好的压缩包解压到C:\\ffmpeg目录下 配置环境变量: 按照这篇文章将刚才的目录添加入Path 测试运行: 按WIN+R,输入CMD,在跳出来的终端窗口中输入ffmpeg -version 如有信息则说明安装成功 MAC用户: 下载安装homebrew: 打开Termial,输入/usr/bin/ruby -e &quot;$(curl -fsSL )&quot; 下载安装FFMpeg: 继续在Termial中输入 brew install ffmpeg --with-fdk-aac --with-ffplay --with-freetype --with-libass --with-libquvi --with-libvorbis --with-libvpx --with-opus --with-x265 测试运行: 继续Terminal中输入ffmpeg -version 如有信息则说明安装成功 打时间轴,得到到字幕文件请参考以下视频进行相关学习,以懂得如何为文本配上时间轴并得到.ass字幕文件为目标.样式和特效如果自己有感兴趣的话可以深究一下,这是一个无底洞. 把字幕压进视频轨用cd命令将终端位置调到视频文件夹,下面是一个例子.C:\\Users\\break\\Videos```如果遇到了什么问题,请打开参考文献[4]看一下其中有没有提到,如果有很奇怪的问题欢迎Email我. 参考文献: FFmpeg安装（windows环境） 在mac os下使用FFmpeg Use ffmpeg to add text subtitles - StackOverflow 使用FFmpeg将字幕文件集成到视频文件 "},{"title":"车牌识别","date":"2018-10-14T04:28:30.000Z","url":"/2018/10/14/lisense_plate_recognition/","tags":["Computer Vision","Python"],"categories":["AI"],"content":"一筹莫展。 Part 1我一开始是想自己去训练这个车牌识别的的 这是Part1的主要内容 生成车牌为什么要生成车牌，因为车牌和人脸不一样，车牌的数据比较隐私，国内并没有说有任何公开的 可以拿来训练车牌的数据集，也没有时间慢慢去收集、标注，只能自己来生成。end-to-end-for-chinese-plate-recognition这个项目里面的”genplate.py”可以模拟生成车牌并附带坐标信息. 判断车牌位置用FasterRcnn训练模型，结果还可以 问题框出车牌之后不知道如何训练了Orz 具体的字符识别和车牌矫正都没有比较好的数据。 Part 2然后我就去找了一些开源项目，主要是EasyPR 和 HyperLPR。考量之后是HyperLPR比较好。使用方法也非常简单，运行demo.py就可以了。 参考文献:文中提到的两个github项目的文档"},{"title":"宁诺公众号大全","date":"2018-07-02T02:28:30.000Z","url":"/2018/07/02/miunottingham_logos_gzh/","tags":["Python","UNNC"],"categories":["Media"],"content":"此博文解释权由MiuNottingham所有。 LOGO图 高清版点此 链接列表部分非微信订阅号账户此处链接无效，会在后期更新中改进。 组织Enactus UNNCHealthyUunnciSSocUNNCNUTSChinaSESASPDPO诺丁汉SSCUNNCStudentsUnionUNNC青年志愿者协会宁波诺丁汉大学校友会宁诺FinanceClub宁诺NewsAgencyUNNC校园大使宁诺校团委宁诺研究生联合会宁诺艺术团中国华东区ACCA Club学生会SUSU(福利向)UNNC_BSA我们的VAVAIESEC 诺丁汉 不方便分类行者无疆(Enactus UNNC)unnc_Uzone宁诺交响乐团UNNC纪念品商店Peekaboo_UNNCUNNC风扇研究UjoyPixelYEA青创联盟UNNC分会UNNC脱单机器人传球计划UNNC毕业季1010DoubleTensChinaLifeCycleUNNC纪念品商店老白在宁诺英国诺丁汉市政厅宁诺萧山微信平台-壹伍壹公里ShuffleCrew 学校官方公众号ResidentialCollegeUNNC宁诺英语语言教学中心SEO学生发展中心UNNCSportsUNNCTheHub宁波诺丁汉大学ITServices宁波诺丁汉大学理工学院宁波诺丁汉大学人文社科学院FHSS宁波诺丁汉大学图书馆宁波诺丁汉大学招生办宁诺商学院宁诺小U宁诺校团委宁诺研究生联合会 社团CIMA_UNNCDiversityUNNCFashionSocietyNingbo U.F.ONottinGreenMUNA · UNNCRANGERUNNCTEDxUNNCTEPTK199unnc 开拓者诺丁记NottingzineUNNCBoardGameClubUNNCKartingoUNNCKoreansocietyUNNCFilmAssociationUNNCPhotographyUNNCSAUNNC爱中华文化社UNNC壁球社UNNC丶Magic丶SocietyUNNC动漫社UNNC国球社UNNC合气道社团UNNC剑道社UNNC口才与演讲社UNNC篮球社UNNC轮滑社UNNC魔幻厨房社UNNC诺宁平安UNNC棋社UNNC拳击社UNNC日语交流社ACT2UNNC商英社UNNC书画社UNNC书友会UNNC跆拳道社UNNC天协UNNC现视研UNNC小吉他社UNNC音乐协会UNNC羽毛球社UNNC中文辩论社unnc中文角UNNC足球社艾话剧社idrama壁球社UNNC魔方社UNNCUNNC旅游UNNC_PAUNNCAIR宁诺DIY宁诺ESA宁诺PRA宁诺IMA学术平台insightTALKNDUC_UNNCUNNCDBCUNNCHolmes诺丁汉排球宁诺智力谜题联盟诺丁SHARE诺丁汉WEAVER职来职往 宁诺职协宁诺CPU宁诺滑板俱乐部宁诺健身社NPCCUNNC万科俱乐部CANN 一些想说的我们做这个东西，并没有和任何人去做过什么营销，目的在于方便UNNCer查阅UNNC-related的微信公众号。在公众号的挑选过程中，商业营销号我们是第一个避免的，如果漏掉了你所在的团体，而且你所在的团体的确有其价值，请通过下面的联系方式联系我们。 联系我Email: breakertt@outlook.com欢迎报错"},{"title":"魔改(二次开发)FaceNet为己用 - 我的人脸识别学习笔记03 - 完结篇","date":"2018-06-22T09:28:30.000Z","url":"/2018/06/22/face_recognition_03/","tags":["Face Recognition","Computer Vision","Python"],"categories":["AI"],"content":"魔改即是正义！ 本文写于年轻人(也就是我)的第一次加班(谁让我在下班前开始了神经网络的训练呢) 我的魔改成果 face_recognition_with_TCPsocket顺便上个逻辑图 寻找志同道合者并沆瀣一气(不是根据学习笔记02，我已经对FaceNet的使用有了初步的了解。FaceNet自带的Demo用来做人脸数据库并识别人脸已经是很完善的了，所以需要做的改动并没有想象的那么多。我第一步要达到的是能在本地提取一个人并输入照片的时候可以返回框出人脸并带上人名的图像，基于这个目的，我去Github上搜索了一些同样是基于FaceNet二次开发的项目。 首先找到的是shanren7的一个实时人脸识别的项目，这个项目和我需要的基本一致，但是问题有二: 只能输出一个人QAQ 用的预训练模型并不是davidsandberg/facenet内提供的 然后我继续寻找，找到了借鉴了shanren7项目开发的另一个项目bearsprogrammer/real-time-deep-face-recognition.这个项目正好解决了前一个提到的两个问题，但是同时也出现了一些其他的问题. 开发者用Python程序内定义好的list来储存人名，要实时更新并不方便。 这个系统是纯本地的，但是我要做的系统是可以远程训练和识别的。 其中问题一其实只是一个小问题，很快就能搞定；而问题二基本上是开发一个新功能了，工作量比较大，也摸了好几天。 需要一提的是，这两个项目的主要的Detect的程序也是由FaceNet的demo修改而来。 那接下来就来对这个项目进行进一步的开发！ 问题一对于问题一的解决，在数据量不大的时候最好的方案就是把这个list单独搞一个文本文件，在每次识别的时候读取为list(数据量上去就要用数据库了)。选择有两个，json和csv，因为我这个字段只有一个编号和人名，用csv比较清爽所以就这么决定了。Python对csv的调用非常简单了，代码如下: 读取追加问题一就这样解决了! 问题二远程检测在我把问题一解决之后，老板说:那你给这个项目加个Socket，然后我就一脸懵逼:Socket是啥???然后我就去百度了一波。Socket其实是一种对TCP/IP的封装，要给我的项目加上Socket，也就是加上通过网络检测和训练的功能。C我是不太熟的，Python也有现成的Socket库，那就用Python了。关于Python上Socket的编写，我很大程度上参考了简书上的一篇文章,同样都是传输图像。啃了一个下午，总算是把检测部分的代码搞了出来，并在本机检测通过，中间有几个我觉得值得一提的小波折。 1.图像文件之后发送过去之后,文件体积一致,但是文件头里面多了一些之前的传输信息,花了一个小时debug总算是找到了问题所在。修改前修改后问题就在于没有对socket接收的缓存数据进行清空 2.Ubuntu的防火墙:要现在本机的防火墙上先开放要使用的端口 本机测试通过了,我就开始拿笔记本远程调试,中间出现了一些因为python版本导致的问题，就不具体说了，请看此,解决这个问题之后程序跑的十分顺利。 远程登记人脸我的想法是调用电脑的摄像头存下一系列照片然后打包成.zip发送给服务器，然后进行人脸对齐和特征的储存。中间基本上没遇到什么太大的问题。 优化之前无论哪个操作，服务器端都是直接用Python调用命令，这样每次都是要重新打开一个TensorFlow的Session，耗时很不乐观。所以我决定人脸检测这部分一直使用同一个Session，训练的时候再重开另一个Session。这样就会出现一个问题，就是每次人脸登记完之后要重新加载包含人名的.csv和包含人脸特征的.pkls,所以我在代码中添加了一个update的变量让程序知道是否要重新加载。为了更好的交互，我第一次接触了Visual Studio并配好了Opencv，步履维艰的写下了自己人生中第一个C++程序，想必以后还有的是打交道的机会。这个C++的控制台小程序可以调用client_dete.py和client_train.py。 后记Github里面总算是有了个不少是自己写的代码的项目，完结撒花！ 参考文献: shanren7/real_time_face_recognition bearsprogrammer/real-time-deep-face-recognition TCP/IP、Http、Socket的区别 [毕设记录] python利用socket进行文件传输 "},{"title":"FaceNet使用记录 - 我的人脸识别学习笔记02","date":"2018-06-19T03:30:30.000Z","url":"/2018/06/19/face_recognition_02/","tags":["Face Recognition","Computer Vision","Python"],"categories":["AI"],"content":"即使是用别人的东西也花了好大的气力。 首先贴上FaceNet的github davidsandberg/facenet 论文 为什么是FaceNet? 机器环境老板给的机器已经配好了 TensorFlow + Cuda, FaceNet所需的环境正好是这个 √ 社区资源Github上使用FaceNet进行二次开发的样例非常多例如:shanren7 bearsprogrammer 识别率和预处理模型的提供FaceNet提供的预处理模型在LFW测试数据集上的准确度已经达到了99.65%,并且提供了分别以 CASIA-WebFace 和 VGGFace2 为训练集的预处理模型. 功能性人脸识别主要有两块，一个是对脸的识别，另一个是对人物的ID的识别.FaceNet在这两个功能上都有很好的完成度 FaceNet的基本使用(此节主要借鉴facenet的wiki)此处已经默认装好了相关Python库以及Tensorflow 1. 克隆 FaceNet 的 Github 库 2. 比对两个人脸的欧式距离FaceNet是采用CNN神经网络将人脸图像映射到128维的欧几里得空间，我们可以根据两幅人像的欧几里得距离去判断两个人像的相似程度。两个人像之间的欧几里得距离越近，说明它们越相似。一般欧式距离小于1,就可以认为是同一个人。 3. 训练自己的数据训练集的结构训练集的结构如下，每个人都有独立的文件夹 剪切出人脸FaceNet 提供了使用 MTCNN 对齐人脸的脚本 代码如下加速多线程版： 训练.pkl 测试 后记既然已经大概了解FaceNet怎么用了，就要开始真正的魔改应用之路了！下回见分晓。 参考文献: 谷歌人脸识别系统FaceNet解析 史上最全的FaceNet源码使用方法和讲解（一）（附预训练模型下载） 人脸识别（Facenet） FaceNet—深度学习与人脸识别的二次结合 "},{"title":"人脸识别的神经网络了解一下啦 - 我的人脸识别学习笔记01","date":"2018-06-07T06:16:50.000Z","url":"/2018/06/07/face_recognition_01/","tags":["Face Recognition","Computer Vision"],"categories":["AI"],"content":"面向谷歌、百度、github、Stackoverflow编程 前言想了一想，离高考结束也已经一年零几天了。在水校的一年也并没有学到什么，算是又荒废了一年光阴。因此决定建一个博客，督促自己不断学习而非继续碌碌无为。 期末考试大概是5月25日考完的，在家休息了大概一个星期之后，终于来到了实习单位，之前也略闻过计算机行业的办公方式，但亲眼看见却又是另外一种感觉了。实习是从6月4日开始的，到了boss便让我去了解一下人脸识别和神经网络方面的东西，特别指出了Faster R-CNN什么的，当然至今还是云里雾里。 既然老板让我去看，我便花了一个早上去看这是个什么东西。要了解Faster R-CNN,还是要从图像识别和分类技术发展的祖先一步步来：CNN→R-CNN→Fast R-CNN→Faster R-CNN 一些神经网络CNNCNN(ConvNet/卷积神经网络)是图像识别的初代算法，主要操作有以下几个，若想详细的了解，可以直接拉到最下看参考.在我这个只了解一下理论暂不实践的半吊子看来主要有以下几步 卷积 也就是用不同滤波器对图像进行特征提取 ReLU ReLU很操作很容易理解 就是把图像里面的每个像素的值范围进行再一次的框定 但是为什么要这么操作我至今也是一知半解 池化 我的理解是对上一个卷积层的图像进行Downscale 全连接层/多层感知器 组合多个层获得神经网络，这块是我最不懂的，至今毫无头绪 无尽重复！ R-CNNR是Regions，从现在开始我们不仅可以知道这图片有啥，更能知道图片里面的东西位置在哪里了。那么是如何做到的呢？ 寻找候选框 对图片进行滑动窗口操作获得潜在的正确答案 CNN 输入CNN神经网络，得到输出 分类与边界回归 先得到正确的区域，显然正确答案会有很多种，所以我们需要边界回归，得到最终的精确答案 事情很显然了，这样既浪费空间又浪费时间又浪费算力。 Fast R-CNN其实这之前还有个SSP-Net，优点 1.多尺度输入图像 2.一次CNN，然后再去找正确答案。然后整合了一些流程，具体的我也并没有非常明白，因为没有用tensorflow实实在在造过这个轮子。 Faster R-CNN速度的问题其实还是在于选框上，所以干脆把选框也交给CNN，这就是Faster R-CNN了 MTCNN但是我要做的是人脸检测，目前人脸检测用的最多的还是MTCNN(OpenFace,FaceNet),和前面几个算法对于人脸进行了再次优化，算法流程如下。 后记这便是我实习第一天看的东西了。但是呢理解往往是相对容易的，但操作起来是举步维艰的。如果是从头造轮子，我的数学以及编程功力都没到位，希望能在两年后的现在有这个能力吧。因此我决定识别和模型搭建这块先用谷歌开源的FaceNet以及其提供的预处理算法开完成老板给我的任务，老板也表示了同意。 参考文献:1.见过最好的神经网络CNN解释2.RCNN介绍3.基于深度学习的目标检测技术演进：R-CNN、Fast R-CNN、Faster R-CNN4.人脸检测：MTCNN"}]